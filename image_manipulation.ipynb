{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c6df69c",
   "metadata": {},
   "source": [
    "# Image content manipulation\n",
    "\n",
    "This project demonstrates the usage of image manipulation by image segmentation and content creation in those selected areas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4742765",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from transformers import SamModel, SamProcessor\n",
    "from diffusers import DiffusionPipeline, AutoPipelineForText2Image, AutoPipelineForInpainting\n",
    "from diffusers.utils import load_image, make_image_grid\n",
    "\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4444b44e",
   "metadata": {},
   "source": [
    "## SAM\n",
    "\n",
    "In order to swiftly segment objects from arbitrary images, SAM or segment anything from Meta, as shown an outstanding performance. Its qualities are being used instead a different or self established model, to keep the code parts streamlined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e37037aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = SamModel.from_pretrained(\"facebook/sam-vit-huge\").to(device)\n",
    "processor = SamProcessor.from_pretrained(\"facebook/sam-vit-huge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e647b2",
   "metadata": {},
   "source": [
    "### Extracting the mask\n",
    "\n",
    "After SAM has been loaded, the segmented mask will be extracted for further usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c10aed63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_to_rgb(mask):\n",
    "    \"\"\"\n",
    "    Transforms a binary mask into an RGBA image for visualization\n",
    "    \"\"\"\n",
    "    \n",
    "    bg_transparent = np.zeros(mask.shape + (4, ), dtype=np.uint8)\n",
    "    \n",
    "    # Remove image content by drawing it green\n",
    "    bg_transparent[mask == 1] = [0, 255, 0, 127]\n",
    "    \n",
    "    return bg_transparent\n",
    "\n",
    "\n",
    "def get_processed_inputs(image, input_points):\n",
    "    inputs = processor(image, input_points=input_points, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    masks = processor.image_processor.post_process_masks(\n",
    "       outputs.pred_masks.cpu(), \n",
    "       inputs[\"original_sizes\"].cpu(), \n",
    "       inputs[\"reshaped_input_sizes\"].cpu()\n",
    "    )\n",
    "    \n",
    "    # Work with the most likeliest score\n",
    "    best_mask = masks[0][0][outputs.iou_scores.argmax()] \n",
    "    return ~best_mask.cpu().numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4e2822c",
   "metadata": {},
   "source": [
    "Running an examplary segmentation of the following object\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cea615b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=128x128>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_image_test = Image.open(\"car.png\").convert(\"RGB\").resize((512, 512))\n",
    "\n",
    "# These are the coordinates of two points on the car\n",
    "input_points_test = [[[150, 170], [300, 250]]]\n",
    "\n",
    "mask_test = get_processed_inputs(raw_image_test, input_points_test)\n",
    "\n",
    "Image.fromarray(mask_to_rgb(mask_test)).resize((128, 128))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bb0fb5",
   "metadata": {},
   "source": [
    "## Inpainting\n",
    "\n",
    "After the segmentation part is being secured, the image manipulation needs to be prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301bf035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c13015e9881a4cf1865d15ecdb527490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 18 files:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline = AutoPipelineForInpainting.from_pretrained(\n",
    "   \"diffusers/stable-diffusion-xl-1.0-inpainting-0.1\",\n",
    "    torch_dtype=torch.float16\n",
    ").to(device)\n",
    "pipeline.enable_model_cpu_offload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224b2928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inpaint(raw_image, input_mask, prompt, negative_prompt=None, seed=74294536, cfgs=7):\n",
    "    \n",
    "    mask_image = Image.fromarray(input_mask)\n",
    "    \n",
    "    rand_gen = torch.manual_seed(seed)\n",
    "    \n",
    "    image = pipeline(\n",
    "        image=raw_image,\n",
    "        mask_image=mask_image,\n",
    "        prompt=prompt,\n",
    "        negative_prompt=negative_prompt if (negative_prompt is not None) else [],\n",
    "        rand_gen=rand_gen,\n",
    "        cfgs=cfgs\n",
    "    ).images[0]\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ca6efe",
   "metadata": {},
   "source": [
    "Completing the experiment with a prompt that describes what should be changed within the original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bb51e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_test = \"a car driving on Mars. Studio lights, 1970s\"\n",
    "negative_prompt_test = \"artifacts, low quality, distortion\"\n",
    "\n",
    "image = inpaint(raw_image_test, mask_test, prompt_test, negative_prompt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d87a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_image_grid([raw_image_test, Image.fromarray(mask_to_rgb(mask_test)), image.resize((512, 512))], rows=1, cols=3)\n",
    "fig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "genai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
